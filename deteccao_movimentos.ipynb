{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1227b330",
   "metadata": {},
   "source": [
    "## Detecção de movimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473252fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767904573.643443 14573762 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando video: /Users/luizviana/tech_chall_4/Unlocking Facial Recognition_ Diverse Activities Analysis.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando video:   0%|          | 0/3326 [00:00<?, ?it/s]W0000 00:00:1767904573.727617 14573934 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1767904573.740829 14573934 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1767904573.754459 14573934 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Processando video: 100%|██████████| 3326/3326 [01:46<00:00, 31.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video processado e salvo em: /Users/luizviana/tech_chall_4/output_video_reconhecimento_movimentos_v5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "class PoseClassifier:\n",
    "    \"\"\"\n",
    "    Classe para classificar poses e contar movimentos usando landmarks do MediaPipe.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        \n",
    "        # --- Para Agachamento ---\n",
    "        self.current_squat_state = \"standing\" # \"standing\" ou \"squatting\"\n",
    "        self.squats_count = 0\n",
    "\n",
    "        # --- Para Levantamento de Braco ---\n",
    "        self.left_arm_up_state = False\n",
    "        self.right_arm_up_state = False\n",
    "        self.left_arm_raise_count = 0\n",
    "        self.right_arm_raise_count = 0\n",
    "\n",
    "        # --- Para T-Pose ---\n",
    "        self.t_pose_state = False # True quando em T-Pose\n",
    "        self.t_pose_count = 0\n",
    "\n",
    "        # --- Para detecção de Concordancia (Nodding) ---\n",
    "        self.prev_nose_y_relative = None # Posição Y do nariz relativa aos ombros no frame anterior\n",
    "        self.nod_state = \"neutral\" # \"neutral\", \"down\", \"up\"\n",
    "        self.nods_count = 0\n",
    "        self.NOD_THRESHOLD = 0.015 # Deslocamento Y relativo para detectar um nod (ajuste)\n",
    "        self.is_nodding_active = False # Flag para indicar se o movimento está ativo no frame atual\n",
    "\n",
    "        # --- Para detecção de Discordancia (Shaking) ---\n",
    "        self.prev_nose_x_relative = None # Posição X do nariz relativa aos ombros no frame anterior\n",
    "        self.shake_state = \"neutral\" # \"neutral\", \"left\", \"right\"\n",
    "        self.shakes_count = 0\n",
    "        self.SHAKE_THRESHOLD = 0.015 # Deslocamento X relativo para detectar um shake (ajuste)\n",
    "        self.is_shaking_active = False # Flag para indicar se o movimento está ativo no frame atual\n",
    "\n",
    "        # --- Para detecção de Caminhada (Walking) ---\n",
    "        self.left_ankle_relative_y_history = deque(maxlen=5) # Historico para suavizar pos Y do tornozelo esquerdo\n",
    "        self.right_ankle_relative_y_history = deque(maxlen=5) # Historico para suavizar pos Y do tornozelo direito\n",
    "        self.left_step_state = \"down\" # \"up\", \"down\"\n",
    "        self.right_step_state = \"down\" # \"up\", \"down\"\n",
    "        self.walking_steps_count = 0\n",
    "        self.WALK_VERTICAL_MOVEMENT_THRESHOLD = -0.04 # Quanto o tornozelo precisa subir (y menor) para ser \"up\" (ajuste)\n",
    "        self.is_walking = False # Flag para indicar se a pessoa está caminhando ativamente\n",
    "        self.walking_frames_no_step = 0 # Contador para desativar is_walking após inatividade\n",
    "        self.WALK_INACTIVITY_THRESHOLD = 30 # Frames sem detecção de passo para parar de considerar \"walking\"\n",
    "        \n",
    "        # --- Para detecção de Posições Anômalas ---\n",
    "        self.previous_landmarks = None # Armazena landmarks do frame anterior para calcular delta de movimento\n",
    "        self.anomalous_count = 0\n",
    "        self.anomalous_event_active = False # True se uma anomalia esta ativa no momento\n",
    "        self.ANOMALOUS_MOVEMENT_THRESHOLD = 0.8 # Limiar para detectar um movimento brusco (ajuste)\n",
    "\n",
    "        # --- Flags para exibir status no frame atual ---\n",
    "        self.current_primary_pose_label = \"Posicao Desconhecida\"\n",
    "\n",
    "    def calculate_angle(self, a, b, c):\n",
    "        \"\"\"\n",
    "        Calcula o ângulo em graus entre três pontos (a, b, c) com o vértice em b.\n",
    "        Os pontos devem ser objetos de landmark do MediaPipe (x, y, z).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            a_coords = [a.x, a.y]\n",
    "            b_coords = [b.x, b.y]\n",
    "            c_coords = [c.x, c.y]\n",
    "\n",
    "            ba = [a_coords[0] - b_coords[0], a_coords[1] - b_coords[1]]\n",
    "            bc = [c_coords[0] - b_coords[0], c_coords[1] - b_coords[1]]\n",
    "\n",
    "            dot_product = ba[0] * bc[0] + ba[1] * bc[1]\n",
    "            magnitude_ba = math.sqrt(ba[0]**2 + ba[1]**2)\n",
    "            magnitude_bc = math.sqrt(bc[0]**2 + bc[1]**2)\n",
    "\n",
    "            if magnitude_ba == 0 or magnitude_bc == 0:\n",
    "                return 0\n",
    "\n",
    "            angle_rad = math.acos(min(max(dot_product / (magnitude_ba * magnitude_bc), -1.0), 1.0))\n",
    "            angle_deg = math.degrees(angle_rad)\n",
    "            return angle_deg\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    def update_states(self, current_landmarks):\n",
    "        \"\"\"\n",
    "        Atualiza os estados internos de classificação e contadores com base nos landmarks atuais.\n",
    "        \"\"\"\n",
    "        # --- Resetar flags de deteccao para o frame atual ---\n",
    "        self.current_primary_pose_label = \"Posicao Desconhecida\"\n",
    "        self.is_nodding_active = False\n",
    "        self.is_shaking_active = False\n",
    "        # self.is_walking eh um estado mais persistente e tratado abaixo\n",
    "        \n",
    "        # O estado anomalous_event_active so eh resetado se a anomalia nao estiver mais acontecendo.\n",
    "        # Ele controla se o contador ja foi incrementado para o evento atual.\n",
    "\n",
    "        if not current_landmarks: # Apenas verifica se ha landmarks\n",
    "            # Se nao ha landmarks detectados, reseta todos os estados para evitar falsos positivos\n",
    "            self.prev_nose_y_relative = None\n",
    "            self.prev_nose_x_relative = None\n",
    "            self.nod_state = \"neutral\"\n",
    "            self.shake_state = \"neutral\"\n",
    "\n",
    "            self.left_ankle_relative_y_history.clear()\n",
    "            self.right_ankle_relative_y_history.clear()\n",
    "            self.left_step_state = \"down\"\n",
    "            self.right_step_state = \"down\"\n",
    "            self.is_walking = False\n",
    "            self.walking_frames_no_step = 0\n",
    "            \n",
    "            self.previous_landmarks = None # Reseta landmarks anteriores para evitar salto apos reaparicao\n",
    "            self.anomalous_event_active = False # Reseta estado de anomalia\n",
    "            return\n",
    "\n",
    "        # --- Calcular Magnitude de Movimento para Deteccao de Anomalias ---\n",
    "        current_movement_magnitude = 0.0\n",
    "        if self.previous_landmarks and current_landmarks:\n",
    "            total_movement = 0.0\n",
    "            # Inclui as principais articulacoes para detectar movimento geral do corpo\n",
    "            landmark_indices = [\n",
    "                self.mp_pose.PoseLandmark.LEFT_SHOULDER.value, self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value,\n",
    "                self.mp_pose.PoseLandmark.LEFT_ELBOW.value, self.mp_pose.PoseLandmark.RIGHT_ELBOW.value,\n",
    "                self.mp_pose.PoseLandmark.LEFT_WRIST.value, self.mp_pose.PoseLandmark.RIGHT_WRIST.value,\n",
    "                self.mp_pose.PoseLandmark.LEFT_HIP.value, self.mp_pose.PoseLandmark.RIGHT_HIP.value,\n",
    "                self.mp_pose.PoseLandmark.LEFT_KNEE.value, self.mp_pose.PoseLandmark.RIGHT_KNEE.value,\n",
    "                self.mp_pose.PoseLandmark.LEFT_ANKLE.value, self.mp_pose.PoseLandmark.RIGHT_ANKLE.value,\n",
    "                self.mp_pose.PoseLandmark.NOSE.value\n",
    "            ]\n",
    "            for i in landmark_indices:\n",
    "                if i < len(current_landmarks) and i < len(self.previous_landmarks):\n",
    "                    prev_lm = self.previous_landmarks[i]\n",
    "                    curr_lm = current_landmarks[i]\n",
    "                    # Calcula a distancia euclidiana no plano XY\n",
    "                    distance = math.sqrt((curr_lm.x - prev_lm.x)**2 + (curr_lm.y - prev_lm.y)**2)\n",
    "                    total_movement += distance\n",
    "            current_movement_magnitude = total_movement\n",
    "        \n",
    "        self.previous_landmarks = current_landmarks # Atualiza landmarks anteriores para o proximo frame\n",
    "\n",
    "        # Obter todos os landmarks e calcular angulos necessarios UMA VEZ\n",
    "        try:\n",
    "            # Landmarks da cabeca e ombros para nod/shake\n",
    "            nose = current_landmarks[self.mp_pose.PoseLandmark.NOSE.value]\n",
    "            left_shoulder = current_landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "            right_shoulder = current_landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "            \n",
    "            # Landmarks para agachamento/bracos/t-pose\n",
    "            left_hip = current_landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "            right_hip = current_landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "            left_elbow = current_landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value]\n",
    "            right_elbow = current_landmarks[self.mp_pose.PoseLandmark.RIGHT_ELBOW.value]\n",
    "            left_wrist = current_landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "            right_wrist = current_landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
    "            left_knee = current_landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "            right_knee = current_landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
    "            left_ankle = current_landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "            right_ankle = current_landmarks[self.mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "\n",
    "            # Ponto de referencia para a linha dos ombros (para detecao de cabeca)\n",
    "            shoulder_mid_y = (left_shoulder.y + right_shoulder.y) / 2\n",
    "            shoulder_mid_x = (left_shoulder.x + right_shoulder.x) / 2\n",
    "\n",
    "            # --- Deteccao de Concordancia (Nodding) ---\n",
    "            # Posicao Y do nariz relativa ao meio dos ombros\n",
    "            relative_nose_y = nose.y - shoulder_mid_y\n",
    "            if self.prev_nose_y_relative is not None:\n",
    "                delta_y = relative_nose_y - self.prev_nose_y_relative\n",
    "                if abs(delta_y) > self.NOD_THRESHOLD:\n",
    "                    if delta_y > 0 and self.nod_state == \"neutral\": # Cabeca inclinando para baixo\n",
    "                        self.nod_state = \"down\"\n",
    "                        self.is_nodding_active = True\n",
    "                    elif delta_y < 0 and self.nod_state == \"down\": # Cabeca subindo depois de ir para baixo\n",
    "                        self.nod_state = \"up\"\n",
    "                        self.nods_count += 1\n",
    "                        self.is_nodding_active = True\n",
    "                    elif delta_y > 0 and self.nod_state == \"up\": # Cabeca descendo depois de ir para cima\n",
    "                        self.nod_state = \"down\"\n",
    "                        self.is_nodding_active = True\n",
    "                else: # Se o movimento para, reseta o estado para neutral\n",
    "                    self.nod_state = \"neutral\"\n",
    "            self.prev_nose_y_relative = relative_nose_y\n",
    "\n",
    "            # --- Deteccao de Discordancia (Shaking) ---\n",
    "            # Posicao X do nariz relativa ao meio dos ombros\n",
    "            relative_nose_x = nose.x - shoulder_mid_x\n",
    "            if self.prev_nose_x_relative is not None:\n",
    "                delta_x = relative_nose_x - self.prev_nose_x_relative\n",
    "                if abs(delta_x) > self.SHAKE_THRESHOLD:\n",
    "                    if delta_x < 0 and self.shake_state == \"neutral\": # Cabeca inclinando para a esquerda\n",
    "                        self.shake_state = \"left\"\n",
    "                        self.is_shaking_active = True\n",
    "                    elif delta_x > 0 and self.shake_state == \"left\": # Cabeca indo para a direita depois de ir para a esquerda\n",
    "                        self.shake_state = \"right\"\n",
    "                        self.shakes_count += 1\n",
    "                        self.is_shaking_active = True\n",
    "                    elif delta_x < 0 and self.shake_state == \"right\": # Cabeca indo para a esquerda depois de ir para a direita\n",
    "                        self.shake_state = \"left\"\n",
    "                        self.is_shaking_active = True\n",
    "                else: # Se o movimento para, reseta o estado para neutral\n",
    "                    self.shake_state = \"neutral\"\n",
    "            self.prev_nose_x_relative = relative_nose_x\n",
    "\n",
    "            # --- Deteccao de Caminhada (Walking) ---\n",
    "            # Calcular posicoes Y dos tornozelos relativas aos quadris correspondentes\n",
    "            relative_left_ankle_to_hip = left_ankle.y - left_hip.y\n",
    "            relative_right_ankle_to_hip = right_ankle.y - right_hip.y\n",
    "\n",
    "            # Adicionar ao historico para suavizacao\n",
    "            self.left_ankle_relative_y_history.append(relative_left_ankle_to_hip)\n",
    "            self.right_ankle_relative_y_history.append(relative_right_ankle_to_hip)\n",
    "\n",
    "            # Usar media do historico para deteccao de levantamento do pe\n",
    "            if len(self.left_ankle_relative_y_history) == self.left_ankle_relative_y_history.maxlen:\n",
    "                avg_left_ankle_y_rel = sum(self.left_ankle_relative_y_history) / len(self.left_ankle_relative_y_history)\n",
    "                avg_right_ankle_y_rel = sum(self.right_ankle_relative_y_history) / len(self.right_ankle_relative_y_history)\n",
    "\n",
    "                # Deteccao para o pe esquerdo\n",
    "                if avg_left_ankle_y_rel < self.WALK_VERTICAL_MOVEMENT_THRESHOLD and self.left_step_state == \"down\":\n",
    "                    self.left_step_state = \"up\"\n",
    "                    self.is_walking = True\n",
    "                    self.walking_frames_no_step = 0\n",
    "                elif avg_left_ankle_y_rel >= self.WALK_VERTICAL_MOVEMENT_THRESHOLD and self.left_step_state == \"up\":\n",
    "                    self.left_step_state = \"down\"\n",
    "                    self.walking_steps_count += 1\n",
    "                    self.is_walking = True\n",
    "                    self.walking_frames_no_step = 0\n",
    "                \n",
    "                # Deteccao para o pe direito\n",
    "                if avg_right_ankle_y_rel < self.WALK_VERTICAL_MOVEMENT_THRESHOLD and self.right_step_state == \"down\":\n",
    "                    self.right_step_state = \"up\"\n",
    "                    self.is_walking = True\n",
    "                    self.walking_frames_no_step = 0\n",
    "                elif avg_right_ankle_y_rel >= self.WALK_VERTICAL_MOVEMENT_THRESHOLD and self.right_step_state == \"up\":\n",
    "                    self.right_step_state = \"down\"\n",
    "                    self.walking_steps_count += 1\n",
    "                    self.is_walking = True\n",
    "                    self.walking_frames_no_step = 0\n",
    "            \n",
    "            # Logica para detectar o fim da caminhada\n",
    "            if self.is_walking:\n",
    "                self.walking_frames_no_step += 1\n",
    "                if self.walking_frames_no_step > self.WALK_INACTIVITY_THRESHOLD:\n",
    "                    self.is_walking = False\n",
    "                    self.walking_frames_no_step = 0\n",
    "\n",
    "            # --- Classificacoes de Poses Individuais ---\n",
    "            # Prioridade: Agachamento > T-Pose > Braco Levantado\n",
    "            \n",
    "            # 1. Agachamento (Squat)\n",
    "            SQUAT_ANGLE_THRESHOLD = 100\n",
    "            STAND_ANGLE_THRESHOLD = 160\n",
    "            \n",
    "            # Calcular angulos para as poses (so se nao houver um erro antes)\n",
    "            left_arm_angle = self.calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_arm_angle = self.calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "            left_knee_angle = self.calculate_angle(left_hip, left_knee, left_ankle)\n",
    "            right_knee_angle = self.calculate_angle(right_hip, right_knee, right_ankle)\n",
    "\n",
    "            is_squatting_frame = (left_knee_angle < SQUAT_ANGLE_THRESHOLD and right_knee_angle < SQUAT_ANGLE_THRESHOLD and \n",
    "                                    left_hip.y > left_knee.y and right_hip.y > right_knee.y)\n",
    "\n",
    "            if is_squatting_frame:\n",
    "                if self.current_squat_state == \"standing\":\n",
    "                    self.current_squat_state = \"squatting\"\n",
    "                self.current_primary_pose_label = \"Agachamento\"\n",
    "            elif self.current_squat_state == \"squatting\" and \\\n",
    "                    left_knee_angle > STAND_ANGLE_THRESHOLD and right_knee_angle > STAND_ANGLE_THRESHOLD:\n",
    "                self.squats_count += 1\n",
    "                self.current_squat_state = \"standing\"\n",
    "            else:\n",
    "                if self.current_squat_state == \"squatting\":\n",
    "                    self.current_primary_pose_label = \"Agachamento\"\n",
    "                else:\n",
    "                    self.current_squat_state = \"standing\"\n",
    "\n",
    "            # 2. T-Pose\n",
    "            if self.current_primary_pose_label == \"Posicao Desconhecida\": # Só classifica se nenhuma outra pose principal foi detectada\n",
    "                T_POSE_ARM_ANGLE_THRESHOLD = 160\n",
    "                T_POSE_Y_DIFF_THRESHOLD = 0.05\n",
    "\n",
    "                arms_straight = left_arm_angle > T_POSE_ARM_ANGLE_THRESHOLD and right_arm_angle > T_POSE_ARM_ANGLE_THRESHOLD\n",
    "                wrists_at_shoulder_height = (abs(left_wrist.y - left_shoulder.y) < T_POSE_Y_DIFF_THRESHOLD) and \\\n",
    "                                            (abs(right_wrist.y - right_shoulder.y) < T_POSE_Y_DIFF_THRESHOLD)\n",
    "                wrists_x_distance_ok = (left_wrist.x < left_shoulder.x and right_wrist.x > right_shoulder.x)\n",
    "                \n",
    "                if arms_straight and wrists_at_shoulder_height and wrists_x_distance_ok:\n",
    "                    if not self.t_pose_state:\n",
    "                        self.t_pose_count += 1\n",
    "                        self.t_pose_state = True\n",
    "                    self.current_primary_pose_label = \"T-Pose\"\n",
    "                else:\n",
    "                    self.t_pose_state = False\n",
    "\n",
    "            # 3. Braco Levantado (Left/Right/Both)\n",
    "            if self.current_primary_pose_label == \"Posicao Desconhecida\": # Só classifica se nenhuma outra pose principal foi detectada\n",
    "                Y_OFFSET_THRESHOLD = 0.1 \n",
    "                left_arm_raised = left_wrist.y < left_shoulder.y - Y_OFFSET_THRESHOLD\n",
    "                right_arm_raised = right_wrist.y < right_shoulder.y - Y_OFFSET_THRESHOLD\n",
    "                \n",
    "                if left_arm_raised and right_arm_raised:\n",
    "                    self.current_primary_pose_label = \"Ambos Bracos Levantados\"\n",
    "                    if not self.left_arm_up_state: # Verifica se ambos estavam pra baixo\n",
    "                        self.left_arm_raise_count += 1 # Contagem única para o movimento\n",
    "                        self.right_arm_raise_count += 1\n",
    "                    self.left_arm_up_state = True\n",
    "                    self.right_arm_up_state = True\n",
    "                elif left_arm_raised:\n",
    "                    self.current_primary_pose_label = \"Braco Esquerdo Levantado\"\n",
    "                    if not self.left_arm_up_state:\n",
    "                        self.left_arm_raise_count += 1\n",
    "                    self.left_arm_up_state = True\n",
    "                    self.right_arm_up_state = False # Garante que o outro braço não está marcado como levantado\n",
    "                elif right_arm_raised:\n",
    "                    self.current_primary_pose_label = \"Braco Direito Levantado\"\n",
    "                    if not self.right_arm_up_state:\n",
    "                        self.right_arm_raise_count += 1\n",
    "                    self.right_arm_up_state = True\n",
    "                    self.left_arm_up_state = False # Garante que o outro braço não está marcado como levantado\n",
    "                else:\n",
    "                    self.left_arm_up_state = False\n",
    "                    self.right_arm_up_state = False\n",
    "            \n",
    "            # --- Deteccao de Anomalias ---\n",
    "            # Deve ser verificada depois de todas as outras deteccoes especificas\n",
    "            # para garantir que nao estamos contando movimentos \"normais\" como anomalias.\n",
    "            is_any_specific_movement_active = (\n",
    "                self.is_nodding_active or\n",
    "                self.is_shaking_active or\n",
    "                self.is_walking or\n",
    "                (self.current_squat_state == \"squatting\") or # Ativo agachando\n",
    "                (self.t_pose_state) # Em T-Pose\n",
    "            )\n",
    "\n",
    "            # Se ha um movimento brusco E nao estamos em nenhuma das acoes especificas\n",
    "            # E a pose principal ainda nao foi classificada por uma pose especifica mais estatica\n",
    "            if current_movement_magnitude > self.ANOMALOUS_MOVEMENT_THRESHOLD and \\\n",
    "               not is_any_specific_movement_active and \\\n",
    "               self.current_primary_pose_label == \"Posicao Desconhecida\":\n",
    "                \n",
    "                if not self.anomalous_event_active:\n",
    "                    self.anomalous_count += 1\n",
    "                    self.anomalous_event_active = True\n",
    "                self.current_primary_pose_label = \"Anomalia Detectada\" # Prioriza esta label\n",
    "            else:\n",
    "                self.anomalous_event_active = False # Reseta se a anomalia nao esta mais ativa\n",
    "\n",
    "        except Exception as e:\n",
    "            # print(f\"Aviso: Erro na classificacao da pose: {e}. Alguns landmarks podem estar ausentes.\")\n",
    "            pass\n",
    "\n",
    "\n",
    "def detect_pose_and_count_movements(input_video_path, output_video_movimentos_path):\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Erro: Nao foi possivel abrir o video em {input_video_path}\")\n",
    "        return\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_movimentos_path, fourcc, fps, (width, height))\n",
    "\n",
    "    pose_classifier = PoseClassifier()\n",
    "\n",
    "    frame_count = 0 # Inicializa o contador de frames\n",
    "\n",
    "    for _ in tqdm(range(total_frames), desc=\"Processando video\"):\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1 # Incrementa o contador de frames a cada iteração\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        rgb_frame.flags.writeable = False\n",
    "\n",
    "        results = pose.process(rgb_frame)\n",
    "        \n",
    "        rgb_frame.flags.writeable = True\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                      mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "            \n",
    "            pose_classifier.update_states(results.pose_landmarks.landmark)\n",
    "        else:\n",
    "            # Se nao ha landmarks, chama update_states com None para resetar os estados\n",
    "            pose_classifier.update_states(None)\n",
    "\n",
    "        # --- Exibir a classificacao e as contagens no frame ---\n",
    "        # Exibir o numero do frame analisado na parte inferior esquerda, em preto\n",
    "        cv2.putText(frame, f'Frame: {frame_count}', (10, height - 30), # Posição (x, y) para o canto inferior esquerdo\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2, cv2.LINE_AA) # Cor preta (0,0,0)\n",
    "        \n",
    "        # As demais informacoes de pose e movimento (posições ajustadas)\n",
    "        cv2.putText(frame, f'Pose Principal: {pose_classifier.current_primary_pose_label}', (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'Agachamentos: {pose_classifier.squats_count}', (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'Braco Esquerdo Levantado: {pose_classifier.left_arm_raise_count}', (10, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'Braco Direito Levantado: {pose_classifier.right_arm_raise_count}', (10, 120),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'T-Poses: {pose_classifier.t_pose_count}', (10, 150),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'Concordancia: {pose_classifier.nods_count} {\"(Ativo)\" if pose_classifier.is_nodding_active else \"\"}', (10, 180),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (120, 20, 220), 2, cv2.LINE_AA) # Roxa\n",
    "        cv2.putText(frame, f'Discordancia: {pose_classifier.shakes_count} {\"(Ativo)\" if pose_classifier.is_shaking_active else \"\"}', (10, 210),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (20, 220, 120), 2, cv2.LINE_AA) # Verde Agua\n",
    "        cv2.putText(frame, f'Passos: {pose_classifier.walking_steps_count} {\"(Caminhando)\" if pose_classifier.is_walking else \"\"}', (10, 240),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 100, 0), 2, cv2.LINE_AA) # Azul\n",
    "        \n",
    "        # Nova linha para o contador de Anomalias\n",
    "        cv2.putText(frame, f'Anomalias: {pose_classifier.anomalous_count} {\"(Ativo)\" if pose_classifier.anomalous_event_active else \"\"}', (10, 270),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA) # Vermelho para Anomalias\n",
    "\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('Video de Classificacao de Movimento', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Caminho para o video de entrada e saida\n",
    "script_dir = os.getcwd()\n",
    "input_video_path = os.path.join(script_dir, 'Unlocking Facial Recognition_ Diverse Activities Analysis.mp4')\n",
    "output_video_movimentos_path = os.path.join(script_dir, 'output_video_reconhecimento_movimentos.mp4')\n",
    "\n",
    "print(f\"Processando video: {input_video_path}\")\n",
    "detect_pose_and_count_movements(input_video_path, output_video_movimentos_path)\n",
    "print(f\"Video processado e salvo em: {output_video_movimentos_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
